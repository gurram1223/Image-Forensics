{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "Image.LOAD_TRUNCATED_IMAGES = True\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,Conv3D,MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D,BatchNormalization\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.initializers import he_normal\n",
    "from keras.applications import vgg16 as vgg\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.optimizers import adam\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loss Curves\n",
    "# plt.figure(figsize=[8,6])\n",
    "# plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "# plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "# plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "# plt.xlabel('Epochs ',fontsize=16)\n",
    "# plt.ylabel('Loss',fontsize=16)\n",
    "# plt.title('Loss Curves',fontsize=16)\n",
    "#   \n",
    "# # Accuracy Curves\n",
    "# plt.figure(figsize=[8,6])\n",
    "# plt.plot(history.history['acc'],'r',linewidth=3.0)\n",
    "# plt.plot(history.history['val_acc'],'b',linewidth=3.0)\n",
    "# plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "# plt.xlabel('Epochs ',fontsize=16)\n",
    "# plt.ylabel('Accuracy',fontsize=16)\n",
    "# plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16011380071941213065\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pristine_path = \"C:/Users/Administrator/Documents/Datasets/Image Forensic Challenge/phase-01-training/dataset-dist/phase-01/training/pristine/pristine_128/\"\n",
    "fake_path  = \"C:/Users/Administrator/Documents/Datasets/Image Forensic Challenge/phase-01-training/dataset-dist/phase-01/training/fake/fake_128/\"\n",
    "\n",
    "pristine_images = os.listdir(pristine_path)\n",
    "fake_images = os.listdir(fake_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:07.867791\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "pristine_list = []\n",
    "pr_img = []\n",
    "for file in pristine_images:\n",
    "    try:   \n",
    "        if file != '.DS_Store':\n",
    "            img = Image.open(pristine_path+file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not present\")\n",
    "        \n",
    "    pristine_list.append(np.array(img))\n",
    "    pr_img.append(img) \n",
    "    \n",
    "pristine_array = np.array(pristine_list)   \n",
    "\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:04.241079\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "fake_list = []\n",
    "fk_img = []\n",
    "for file in fake_images:\n",
    "    try:\n",
    "        if file != '.DS_Store':\n",
    "            img = Image.open(fake_path+file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not present\")     \n",
    "    fake_list.append(np.array(img))\n",
    "    fk_img.append(img)\n",
    "\n",
    "fake_array = np.array(fake_list)\n",
    "    \n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048, 128, 128, 3)\n",
      "(450, 128, 128, 3)\n",
      "(128, 128, 3)\n",
      "(128, 128, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(pristine_array.shape)\n",
    "print(fake_array.shape)\n",
    "print(pristine_array[0].shape)\n",
    "print(fake_array[0].shape)\n",
    "print(type(pristine_array))\n",
    "print(type(fake_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1498, 128, 128, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = [0]*1048+[1]*450\n",
    "\n",
    "img_array = []\n",
    "img_array = np.vstack((pristine_array,fake_array))\n",
    "\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(img_array, class_labels, test_size=0.25, stratify=class_labels,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1123, 128, 128, 3)\n",
      "x_test shape: (375, 128, 128, 3)\n",
      "1123 train samples\n",
      "375 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing the data\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = x_train.shape[0]\n",
    "nb_validation_samples = x_test.shape[0]\n",
    "num_classes = 2\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 128, 128\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "    \n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to update the plots for each epoch and error\n",
    "def plt_dynamic(x, vy, ty, ax, fig):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = vgg.VGG16(weights='imagenet',include_top=False,input_shape=x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1a0f2956a58>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1a0ffbe4470>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1a0ffbe42e8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1a086c3b588>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_model.layers[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in vgg16_model.layers:\n",
    "#    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg16_model.layers[7:]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv2D at 0x1a2d2822da0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1a2d2853240>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1a2d2872630>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1a2d2892438>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1a2d2892f98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1a2d28c5470>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1a2d28e16d8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1a2d29004e0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_model.layers[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 260,160\n",
      "Non-trainable params: 14,454,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = vgg16_model.get_layer('block2_pool').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'block2_pool_2/MaxPool:0' shape=(?, 32, 32, 128) dtype=float32>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(vgg16_model)\n",
    "\n",
    "\n",
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=(4, 4, 512)))\n",
    "#model_aug.add(Dropout(0.3))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "\n",
    "top_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.add(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 2)                 2097922   \n",
      "=================================================================\n",
      "Total params: 16,812,610\n",
      "Trainable params: 2,358,082\n",
      "Non-trainable params: 14,454,528\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1123 samples, validate on 375 samples\n",
      "Epoch 1/20\n",
      "1123/1123 [==============================] - 793s 706ms/step - loss: 0.6447 - acc: 0.6794 - val_loss: 0.6246 - val_acc: 0.6933\n",
      "Epoch 2/20\n",
      "1123/1123 [==============================] - 792s 705ms/step - loss: 0.6097 - acc: 0.6990 - val_loss: 0.6099 - val_acc: 0.6773\n",
      "Epoch 3/20\n",
      "1123/1123 [==============================] - 751s 669ms/step - loss: 0.5893 - acc: 0.7044 - val_loss: 0.6011 - val_acc: 0.6933\n",
      "Epoch 4/20\n",
      "1123/1123 [==============================] - 760s 677ms/step - loss: 0.5733 - acc: 0.7044 - val_loss: 0.5966 - val_acc: 0.6880\n",
      "Epoch 5/20\n",
      "1123/1123 [==============================] - 772s 688ms/step - loss: 0.5584 - acc: 0.7115 - val_loss: 0.5913 - val_acc: 0.7067\n",
      "Epoch 6/20\n",
      "1123/1123 [==============================] - 787s 701ms/step - loss: 0.5459 - acc: 0.7106 - val_loss: 0.5869 - val_acc: 0.7093\n",
      "Epoch 7/20\n",
      "1123/1123 [==============================] - 789s 702ms/step - loss: 0.5380 - acc: 0.7266 - val_loss: 0.5876 - val_acc: 0.7093\n",
      "Epoch 8/20\n",
      "1123/1123 [==============================] - 788s 702ms/step - loss: 0.5241 - acc: 0.7293 - val_loss: 0.5814 - val_acc: 0.6960\n",
      "Epoch 9/20\n",
      "1123/1123 [==============================] - 789s 703ms/step - loss: 0.5124 - acc: 0.7382 - val_loss: 0.5771 - val_acc: 0.7093\n",
      "Epoch 10/20\n",
      "1123/1123 [==============================] - 808s 719ms/step - loss: 0.5018 - acc: 0.7507 - val_loss: 0.5749 - val_acc: 0.7120\n",
      "Epoch 11/20\n",
      "1123/1123 [==============================] - 795s 708ms/step - loss: 0.4902 - acc: 0.7569 - val_loss: 0.5727 - val_acc: 0.7173\n",
      "Epoch 12/20\n",
      "1123/1123 [==============================] - 787s 701ms/step - loss: 0.4801 - acc: 0.7605 - val_loss: 0.5686 - val_acc: 0.7147\n",
      "Epoch 13/20\n",
      "1123/1123 [==============================] - 793s 707ms/step - loss: 0.4699 - acc: 0.7720 - val_loss: 0.5680 - val_acc: 0.7200\n",
      "Epoch 14/20\n",
      "1123/1123 [==============================] - 791s 704ms/step - loss: 0.4593 - acc: 0.7747 - val_loss: 0.5655 - val_acc: 0.7200\n",
      "Epoch 15/20\n",
      "1123/1123 [==============================] - 791s 705ms/step - loss: 0.4505 - acc: 0.7890 - val_loss: 0.5636 - val_acc: 0.7200\n",
      "Epoch 16/20\n",
      "1123/1123 [==============================] - 790s 704ms/step - loss: 0.4400 - acc: 0.7854 - val_loss: 0.5622 - val_acc: 0.7173\n",
      "Epoch 17/20\n",
      "1123/1123 [==============================] - 790s 703ms/step - loss: 0.4290 - acc: 0.8077 - val_loss: 0.5601 - val_acc: 0.7280\n",
      "Epoch 18/20\n",
      "1123/1123 [==============================] - 792s 705ms/step - loss: 0.4189 - acc: 0.8085 - val_loss: 0.5587 - val_acc: 0.7227\n",
      "Epoch 19/20\n",
      "1123/1123 [==============================] - 791s 704ms/step - loss: 0.4108 - acc: 0.8237 - val_loss: 0.5591 - val_acc: 0.7307\n",
      "Epoch 20/20\n",
      "1123/1123 [==============================] - 790s 704ms/step - loss: 0.3995 - acc: 0.8388 - val_loss: 0.5571 - val_acc: 0.7307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27a0478a128>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-5), metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5570678871472676\n",
      "Test accuracy: 0.7306666650772095\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-64451d1e6805>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# list of epoch numbers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# print(history.history.keys())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 20\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Binary Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,epochs+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5570678871472676\n",
      "Test accuracy: 0.7306666650772095\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg16_model.layers[7:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model=Sequential()\n",
    "model.add(vgg16_model)\n",
    "\n",
    "\n",
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=(4, 4, 512)))\n",
    "#model_aug.add(Dropout(0.3))\n",
    "top_model.add(Dense(256, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "top_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.add(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 2)                 2097922   \n",
      "=================================================================\n",
      "Total params: 16,812,610\n",
      "Trainable params: 2,358,082\n",
      "Non-trainable params: 14,454,528\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1123 samples, validate on 375 samples\n",
      "Epoch 1/25\n",
      "1123/1123 [==============================] - 805s 716ms/step - loss: 0.6251 - acc: 0.6589 - val_loss: 0.6557 - val_acc: 0.6933\n",
      "Epoch 2/25\n",
      "1123/1123 [==============================] - 798s 711ms/step - loss: 0.6038 - acc: 0.6955 - val_loss: 0.6380 - val_acc: 0.6880\n",
      "Epoch 3/25\n",
      "1123/1123 [==============================] - 802s 714ms/step - loss: 0.5813 - acc: 0.6972 - val_loss: 0.6322 - val_acc: 0.6960\n",
      "Epoch 4/25\n",
      "1123/1123 [==============================] - 788s 702ms/step - loss: 0.5684 - acc: 0.7044 - val_loss: 0.6260 - val_acc: 0.6907\n",
      "Epoch 5/25\n",
      "1123/1123 [==============================] - 765s 681ms/step - loss: 0.5550 - acc: 0.7097 - val_loss: 0.6226 - val_acc: 0.6907\n",
      "Epoch 6/25\n",
      "1123/1123 [==============================] - 892s 794ms/step - loss: 0.5435 - acc: 0.7168 - val_loss: 0.6195 - val_acc: 0.6907\n",
      "Epoch 7/25\n",
      "1123/1123 [==============================] - 846s 753ms/step - loss: 0.5321 - acc: 0.7231 - val_loss: 0.6173 - val_acc: 0.6853\n",
      "Epoch 8/25\n",
      "1123/1123 [==============================] - 800s 713ms/step - loss: 0.5220 - acc: 0.7355 - val_loss: 0.6158 - val_acc: 0.6747\n",
      "Epoch 9/25\n",
      "1123/1123 [==============================] - 802s 714ms/step - loss: 0.5119 - acc: 0.7551 - val_loss: 0.6180 - val_acc: 0.6987\n",
      "Epoch 10/25\n",
      "1123/1123 [==============================] - 799s 712ms/step - loss: 0.5009 - acc: 0.7489 - val_loss: 0.6115 - val_acc: 0.6773\n",
      "Epoch 11/25\n",
      "1123/1123 [==============================] - 799s 711ms/step - loss: 0.4886 - acc: 0.7676 - val_loss: 0.6116 - val_acc: 0.6880\n",
      "Epoch 12/25\n",
      "1123/1123 [==============================] - 793s 706ms/step - loss: 0.4782 - acc: 0.7774 - val_loss: 0.6104 - val_acc: 0.6880\n",
      "Epoch 13/25\n",
      "1123/1123 [==============================] - 816s 726ms/step - loss: 0.4689 - acc: 0.7907 - val_loss: 0.6106 - val_acc: 0.6800\n",
      "Epoch 14/25\n",
      "1123/1123 [==============================] - 801s 713ms/step - loss: 0.4578 - acc: 0.7809 - val_loss: 0.6098 - val_acc: 0.6747\n",
      "Epoch 15/25\n",
      "1123/1123 [==============================] - 805s 717ms/step - loss: 0.4479 - acc: 0.8094 - val_loss: 0.6090 - val_acc: 0.6800\n",
      "Epoch 16/25\n",
      "1123/1123 [==============================] - 807s 719ms/step - loss: 0.4383 - acc: 0.8121 - val_loss: 0.6114 - val_acc: 0.6773\n",
      "Epoch 17/25\n",
      "1123/1123 [==============================] - 811s 722ms/step - loss: 0.4280 - acc: 0.8183 - val_loss: 0.6100 - val_acc: 0.6773\n",
      "Epoch 18/25\n",
      "1123/1123 [==============================] - 804s 716ms/step - loss: 0.4180 - acc: 0.8317 - val_loss: 0.6142 - val_acc: 0.6853\n",
      "Epoch 19/25\n",
      "1123/1123 [==============================] - 799s 712ms/step - loss: 0.4085 - acc: 0.8308 - val_loss: 0.6118 - val_acc: 0.6773\n",
      "Epoch 20/25\n",
      "1123/1123 [==============================] - 800s 712ms/step - loss: 0.3994 - acc: 0.8504 - val_loss: 0.6167 - val_acc: 0.6827\n",
      "Epoch 21/25\n",
      "1123/1123 [==============================] - 799s 712ms/step - loss: 0.3909 - acc: 0.8415 - val_loss: 0.6150 - val_acc: 0.6773\n",
      "Epoch 22/25\n",
      "1123/1123 [==============================] - 798s 710ms/step - loss: 0.3804 - acc: 0.8557 - val_loss: 0.6175 - val_acc: 0.6800\n",
      "Epoch 23/25\n",
      "1123/1123 [==============================] - 801s 714ms/step - loss: 0.3712 - acc: 0.8531 - val_loss: 0.6171 - val_acc: 0.6827\n",
      "Epoch 24/25\n",
      "1123/1123 [==============================] - 799s 711ms/step - loss: 0.3605 - acc: 0.8664 - val_loss: 0.6203 - val_acc: 0.6827\n",
      "Epoch 25/25\n",
      "1123/1123 [==============================] - 800s 713ms/step - loss: 0.3524 - acc: 0.8664 - val_loss: 0.6218 - val_acc: 0.6853\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "batch_size = 64\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-5), metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6218281364440919\n",
      "Test accuracy: 0.6853333347638448\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Binary Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,epochs+1))\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 2)                 2097922   \n",
      "=================================================================\n",
      "Total params: 16,812,610\n",
      "Trainable params: 2,358,082\n",
      "Non-trainable params: 14,454,528\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1123 samples, validate on 375 samples\n",
      "Epoch 1/30\n",
      "1123/1123 [==============================] - 807s 718ms/step - loss: 0.6568 - acc: 0.6589 - val_loss: 0.6352 - val_acc: 0.7013\n",
      "Epoch 2/30\n",
      "1123/1123 [==============================] - 807s 719ms/step - loss: 0.6115 - acc: 0.6919 - val_loss: 0.6187 - val_acc: 0.6987\n",
      "Epoch 3/30\n",
      "1123/1123 [==============================] - 815s 726ms/step - loss: 0.5918 - acc: 0.7017 - val_loss: 0.6104 - val_acc: 0.6960\n",
      "Epoch 4/30\n",
      "1123/1123 [==============================] - 805s 717ms/step - loss: 0.5784 - acc: 0.7079 - val_loss: 0.6071 - val_acc: 0.6933\n",
      "Epoch 5/30\n",
      "1123/1123 [==============================] - 810s 721ms/step - loss: 0.5615 - acc: 0.7088 - val_loss: 0.6028 - val_acc: 0.6907\n",
      "Epoch 6/30\n",
      "1123/1123 [==============================] - 889s 792ms/step - loss: 0.5490 - acc: 0.7248 - val_loss: 0.6026 - val_acc: 0.6880\n",
      "Epoch 7/30\n",
      "1123/1123 [==============================] - 888s 791ms/step - loss: 0.5353 - acc: 0.7195 - val_loss: 0.6002 - val_acc: 0.6853\n",
      "Epoch 8/30\n",
      "1123/1123 [==============================] - 817s 728ms/step - loss: 0.5235 - acc: 0.7311 - val_loss: 0.5987 - val_acc: 0.6907\n",
      "Epoch 9/30\n",
      "1123/1123 [==============================] - 814s 725ms/step - loss: 0.5113 - acc: 0.7498 - val_loss: 0.5976 - val_acc: 0.6827\n",
      "Epoch 10/30\n",
      "1123/1123 [==============================] - 819s 729ms/step - loss: 0.4992 - acc: 0.7516 - val_loss: 0.5973 - val_acc: 0.6853\n",
      "Epoch 11/30\n",
      "1123/1123 [==============================] - 816s 727ms/step - loss: 0.4904 - acc: 0.7569 - val_loss: 0.5989 - val_acc: 0.6827\n",
      "Epoch 12/30\n",
      "1123/1123 [==============================] - 817s 728ms/step - loss: 0.4776 - acc: 0.7747 - val_loss: 0.5963 - val_acc: 0.6853\n",
      "Epoch 13/30\n",
      "1123/1123 [==============================] - 816s 726ms/step - loss: 0.4655 - acc: 0.7827 - val_loss: 0.5960 - val_acc: 0.6827\n",
      "Epoch 14/30\n",
      "1123/1123 [==============================] - 822s 732ms/step - loss: 0.4570 - acc: 0.7783 - val_loss: 0.5954 - val_acc: 0.6880\n",
      "Epoch 15/30\n",
      "1123/1123 [==============================] - 841s 749ms/step - loss: 0.4455 - acc: 0.8264 - val_loss: 0.5967 - val_acc: 0.6827\n",
      "Epoch 16/30\n",
      "1123/1123 [==============================] - 839s 747ms/step - loss: 0.4351 - acc: 0.8068 - val_loss: 0.5961 - val_acc: 0.6800\n",
      "Epoch 17/30\n",
      "1123/1123 [==============================] - 816s 726ms/step - loss: 0.4247 - acc: 0.8059 - val_loss: 0.5969 - val_acc: 0.6800\n",
      "Epoch 18/30\n",
      "1123/1123 [==============================] - 815s 726ms/step - loss: 0.4169 - acc: 0.8210 - val_loss: 0.5977 - val_acc: 0.6827\n",
      "Epoch 19/30\n",
      "1123/1123 [==============================] - 816s 727ms/step - loss: 0.4028 - acc: 0.8370 - val_loss: 0.5966 - val_acc: 0.6800\n",
      "Epoch 20/30\n",
      "1123/1123 [==============================] - 817s 727ms/step - loss: 0.3924 - acc: 0.8272 - val_loss: 0.5977 - val_acc: 0.6907\n",
      "Epoch 21/30\n",
      "1123/1123 [==============================] - 818s 729ms/step - loss: 0.3822 - acc: 0.8513 - val_loss: 0.6005 - val_acc: 0.6880\n",
      "Epoch 22/30\n",
      "1123/1123 [==============================] - 811s 722ms/step - loss: 0.3714 - acc: 0.8477 - val_loss: 0.6006 - val_acc: 0.6960\n",
      "Epoch 23/30\n",
      "1123/1123 [==============================] - 815s 726ms/step - loss: 0.3616 - acc: 0.8557 - val_loss: 0.6021 - val_acc: 0.6933\n",
      "Epoch 24/30\n",
      "1123/1123 [==============================] - 815s 726ms/step - loss: 0.3511 - acc: 0.8629 - val_loss: 0.6054 - val_acc: 0.6933\n",
      "Epoch 25/30\n",
      "1123/1123 [==============================] - 815s 726ms/step - loss: 0.3416 - acc: 0.8753 - val_loss: 0.6054 - val_acc: 0.6907\n",
      "Epoch 26/30\n",
      "1123/1123 [==============================] - 816s 727ms/step - loss: 0.3349 - acc: 0.8736 - val_loss: 0.6102 - val_acc: 0.6827\n",
      "Epoch 27/30\n",
      "1123/1123 [==============================] - 816s 726ms/step - loss: 0.3276 - acc: 0.8923 - val_loss: 0.6114 - val_acc: 0.6853\n",
      "Epoch 28/30\n",
      "1123/1123 [==============================] - 817s 728ms/step - loss: 0.3121 - acc: 0.9029 - val_loss: 0.6137 - val_acc: 0.6853\n",
      "Epoch 29/30\n",
      "1123/1123 [==============================] - 817s 728ms/step - loss: 0.3032 - acc: 0.8976 - val_loss: 0.6157 - val_acc: 0.6907\n",
      "Epoch 30/30\n",
      "1123/1123 [==============================] - 817s 728ms/step - loss: 0.2938 - acc: 0.9154 - val_loss: 0.6303 - val_acc: 0.6933\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 64\n",
    "model=Sequential()\n",
    "model.add(vgg16_model)\n",
    "\n",
    "\n",
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=(4, 4, 512)))\n",
    "#model_aug.add(Dropout(0.3))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "\n",
    "top_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.add(top_model)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-5), metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6303467669487\n",
      "Test accuracy: 0.6933333334922791\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Binary Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,epochs+1))\n",
    "\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "model=Sequential()\n",
    "model.add(vgg16_model)\n",
    "\n",
    "\n",
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=(4, 4, 512)))\n",
    "#model_aug.add(Dropout(0.3))\n",
    "top_model.add(Dense(512, activation='relu'))\n",
    "top_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.add(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "sequential_10 (Sequential)   (None, 2)                 4195842   \n",
      "=================================================================\n",
      "Total params: 18,910,530\n",
      "Trainable params: 4,456,002\n",
      "Non-trainable params: 14,454,528\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1123 samples, validate on 375 samples\n",
      "Epoch 1/30\n",
      "1123/1123 [==============================] - 801s 713ms/step - loss: 0.8309 - acc: 0.3072 - val_loss: 0.7785 - val_acc: 0.3760\n",
      "Epoch 2/30\n",
      "1123/1123 [==============================] - 786s 700ms/step - loss: 0.7432 - acc: 0.3927 - val_loss: 0.7087 - val_acc: 0.4987\n",
      "Epoch 3/30\n",
      "1123/1123 [==============================] - 792s 705ms/step - loss: 0.6872 - acc: 0.5361 - val_loss: 0.6669 - val_acc: 0.6080\n",
      "Epoch 4/30\n",
      "1123/1123 [==============================] - 791s 704ms/step - loss: 0.6563 - acc: 0.6536 - val_loss: 0.6448 - val_acc: 0.6480\n",
      "Epoch 5/30\n",
      "1123/1123 [==============================] - 790s 704ms/step - loss: 0.6391 - acc: 0.6857 - val_loss: 0.6351 - val_acc: 0.6800\n",
      "Epoch 6/30\n",
      "1123/1123 [==============================] - 791s 704ms/step - loss: 0.6320 - acc: 0.6955 - val_loss: 0.6296 - val_acc: 0.6907\n",
      "Epoch 7/30\n",
      "1123/1123 [==============================] - 793s 706ms/step - loss: 0.6273 - acc: 0.6963 - val_loss: 0.6273 - val_acc: 0.6933\n",
      "Epoch 8/30\n",
      "1123/1123 [==============================] - 794s 707ms/step - loss: 0.6250 - acc: 0.6981 - val_loss: 0.6261 - val_acc: 0.6933\n",
      "Epoch 9/30\n",
      "1123/1123 [==============================] - 791s 704ms/step - loss: 0.6233 - acc: 0.6981 - val_loss: 0.6253 - val_acc: 0.6960\n",
      "Epoch 10/30\n",
      "1123/1123 [==============================] - 793s 706ms/step - loss: 0.6217 - acc: 0.6990 - val_loss: 0.6246 - val_acc: 0.6933\n",
      "Epoch 11/30\n",
      "1123/1123 [==============================] - 799s 712ms/step - loss: 0.6202 - acc: 0.6990 - val_loss: 0.6242 - val_acc: 0.6933\n",
      "Epoch 12/30\n",
      "1123/1123 [==============================] - 826s 736ms/step - loss: 0.6189 - acc: 0.6999 - val_loss: 0.6236 - val_acc: 0.6933\n",
      "Epoch 13/30\n",
      "1123/1123 [==============================] - 797s 709ms/step - loss: 0.6176 - acc: 0.6999 - val_loss: 0.6231 - val_acc: 0.6933\n",
      "Epoch 14/30\n",
      "1123/1123 [==============================] - 794s 707ms/step - loss: 0.6161 - acc: 0.6999 - val_loss: 0.6226 - val_acc: 0.6933\n",
      "Epoch 15/30\n",
      "1123/1123 [==============================] - 795s 708ms/step - loss: 0.6149 - acc: 0.6999 - val_loss: 0.6220 - val_acc: 0.6933\n",
      "Epoch 16/30\n",
      "1123/1123 [==============================] - 796s 709ms/step - loss: 0.6135 - acc: 0.6999 - val_loss: 0.6216 - val_acc: 0.6933\n",
      "Epoch 17/30\n",
      "1123/1123 [==============================] - 796s 709ms/step - loss: 0.6121 - acc: 0.7008 - val_loss: 0.6211 - val_acc: 0.6933\n",
      "Epoch 18/30\n",
      "1123/1123 [==============================] - 798s 711ms/step - loss: 0.6107 - acc: 0.7008 - val_loss: 0.6206 - val_acc: 0.6960\n",
      "Epoch 19/30\n",
      "1123/1123 [==============================] - 797s 710ms/step - loss: 0.6093 - acc: 0.7008 - val_loss: 0.6200 - val_acc: 0.6960\n",
      "Epoch 20/30\n",
      "1123/1123 [==============================] - 796s 709ms/step - loss: 0.6080 - acc: 0.7008 - val_loss: 0.6195 - val_acc: 0.6987\n",
      "Epoch 21/30\n",
      "1123/1123 [==============================] - 796s 709ms/step - loss: 0.6066 - acc: 0.7008 - val_loss: 0.6190 - val_acc: 0.6987\n",
      "Epoch 22/30\n",
      "1123/1123 [==============================] - 795s 708ms/step - loss: 0.6052 - acc: 0.7008 - val_loss: 0.6185 - val_acc: 0.6987\n",
      "Epoch 23/30\n",
      "1123/1123 [==============================] - 797s 710ms/step - loss: 0.6040 - acc: 0.7008 - val_loss: 0.6180 - val_acc: 0.6987\n",
      "Epoch 24/30\n",
      "1123/1123 [==============================] - 795s 708ms/step - loss: 0.6025 - acc: 0.7008 - val_loss: 0.6176 - val_acc: 0.6987\n",
      "Epoch 25/30\n",
      "1123/1123 [==============================] - 798s 711ms/step - loss: 0.6011 - acc: 0.7008 - val_loss: 0.6171 - val_acc: 0.6987\n",
      "Epoch 26/30\n",
      "1123/1123 [==============================] - 796s 709ms/step - loss: 0.5998 - acc: 0.7008 - val_loss: 0.6166 - val_acc: 0.6987\n",
      "Epoch 27/30\n",
      "1123/1123 [==============================] - 796s 708ms/step - loss: 0.5984 - acc: 0.7008 - val_loss: 0.6162 - val_acc: 0.6987\n",
      "Epoch 28/30\n",
      "1123/1123 [==============================] - 796s 709ms/step - loss: 0.5970 - acc: 0.7008 - val_loss: 0.6157 - val_acc: 0.6987\n",
      "Epoch 29/30\n",
      "1123/1123 [==============================] - 802s 714ms/step - loss: 0.5958 - acc: 0.7008 - val_loss: 0.6153 - val_acc: 0.6987\n",
      "Epoch 30/30\n",
      "1123/1123 [==============================] - 809s 721ms/step - loss: 0.5949 - acc: 0.7017 - val_loss: 0.6149 - val_acc: 0.6987\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-6), metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=64, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6148993074099223\n",
      "Test accuracy: 0.6986666663487753\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Binary Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,epochs+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1198, 128, 128, 3)\n",
      "x_test shape: (300, 128, 128, 3)\n",
      "1198 train samples\n",
      "300 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(img_array, class_labels, test_size=0.20, stratify=class_labels)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing the data\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "\n",
    "nb_train_samples = x_train.shape[0]\n",
    "nb_validation_samples = x_test.shape[0]\n",
    "num_classes = 2\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 128, 128\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "    \n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "# this function is used to update the plots for each epoch and error\n",
    "def plt_dynamic(x, vy, ty, ax, fig):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = vgg.VGG16(weights='imagenet',include_top=False,input_shape=x_train.shape[1:])\n",
    "vgg16_model.layers[0:7]\n",
    "\n",
    "\n",
    "del model\n",
    "del top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "sequential_6 (Sequential)    (None, 2)                 1048962   \n",
      "=================================================================\n",
      "Total params: 15,763,650\n",
      "Trainable params: 15,763,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#for layer in vgg16_model.layers[7:]:\n",
    "#    layer.trainable = False\n",
    "    \n",
    "model=Sequential()\n",
    "model.add(vgg16_model)\n",
    "\n",
    "\n",
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=(4, 4, 512)))\n",
    "#model_aug.add(Dropout(0.3))\n",
    "top_model.add(Dense(128, activation='relu'))\n",
    "top_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.add(top_model)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-5), metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "18/18 [==============================] - 540s 30s/step - loss: 0.6102 - acc: 0.7170 - val_loss: 0.5995 - val_acc: 0.6967\n",
      "Epoch 2/8\n",
      "18/18 [==============================] - 512s 28s/step - loss: 0.6232 - acc: 0.6858 - val_loss: 0.5959 - val_acc: 0.6967\n",
      "Epoch 3/8\n",
      "18/18 [==============================] - 508s 28s/step - loss: 0.5781 - acc: 0.6876 - val_loss: 0.5903 - val_acc: 0.7000\n",
      "Epoch 4/8\n",
      "18/18 [==============================] - 544s 30s/step - loss: 0.5504 - acc: 0.7188 - val_loss: 0.5859 - val_acc: 0.6967\n",
      "Epoch 5/8\n",
      "18/18 [==============================] - 531s 30s/step - loss: 0.4828 - acc: 0.7735 - val_loss: 0.5743 - val_acc: 0.6867\n",
      "Epoch 6/8\n",
      "18/18 [==============================] - 605s 34s/step - loss: 0.5171 - acc: 0.7257 - val_loss: 0.5977 - val_acc: 0.6733\n",
      "Epoch 7/8\n",
      "18/18 [==============================] - 558s 31s/step - loss: 0.4640 - acc: 0.7884 - val_loss: 0.6167 - val_acc: 0.6900\n",
      "Epoch 8/8\n",
      "18/18 [==============================] - 547s 30s/step - loss: 0.4426 - acc: 0.8090 - val_loss: 0.6314 - val_acc: 0.6867\n"
     ]
    }
   ],
   "source": [
    "epochs = 8\n",
    "batch_size = 64\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history=model.fit_generator(datagen.flow(x_train, y_train),\n",
    "                    steps_per_epoch=nb_train_samples // batch_size, epochs=epochs,validation_data=(x_test, y_test),\n",
    "                           validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1198 samples, validate on 300 samples\n",
      "Epoch 1/8\n",
      "1198/1198 [==============================] - 1041s 869ms/step - loss: 0.3295 - acc: 0.8689 - val_loss: 0.6307 - val_acc: 0.7000\n",
      "Epoch 2/8\n",
      "1198/1198 [==============================] - 1032s 861ms/step - loss: 0.2405 - acc: 0.9240 - val_loss: 0.6827 - val_acc: 0.6900\n",
      "Epoch 3/8\n",
      "1198/1198 [==============================] - 1043s 871ms/step - loss: 0.1633 - acc: 0.9533 - val_loss: 0.7310 - val_acc: 0.6933\n",
      "Epoch 4/8\n",
      "1198/1198 [==============================] - 1045s 873ms/step - loss: 0.1050 - acc: 0.9808 - val_loss: 0.8488 - val_acc: 0.7233\n",
      "Epoch 5/8\n",
      "1198/1198 [==============================] - 1027s 857ms/step - loss: 0.0860 - acc: 0.9800 - val_loss: 0.9912 - val_acc: 0.7000\n",
      "Epoch 6/8\n",
      "1198/1198 [==============================] - 1027s 857ms/step - loss: 0.0731 - acc: 0.9825 - val_loss: 0.9016 - val_acc: 0.6933\n",
      "Epoch 7/8\n",
      "1198/1198 [==============================] - 1029s 859ms/step - loss: 0.0619 - acc: 0.9875 - val_loss: 0.9784 - val_acc: 0.7033\n",
      "Epoch 8/8\n",
      "1198/1198 [==============================] - 1031s 861ms/step - loss: 0.0429 - acc: 0.9875 - val_loss: 0.9984 - val_acc: 0.7033\n"
     ]
    }
   ],
   "source": [
    "epochs = 8\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=64, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9983818833033243\n",
      "Test accuracy: 0.7033333325386047\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Binary Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,epochs+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = vgg.VGG16(weights='imagenet',include_top=False,input_shape=x_train.shape[1:])\n",
    "vgg16_model.layers[0:7]\n",
    "\n",
    "\n",
    "del model\n",
    "del top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "sequential_8 (Sequential)    (None, 2)                 1048962   \n",
      "=================================================================\n",
      "Total params: 15,763,650\n",
      "Trainable params: 15,763,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#for layer in vgg16_model.layers[7:]:\n",
    "#    layer.trainable = False\n",
    "    \n",
    "model=Sequential()\n",
    "model.add(vgg16_model)\n",
    "\n",
    "\n",
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=(4, 4, 512)))\n",
    "#model_aug.add(Dropout(0.3))\n",
    "top_model.add(Dense(128, activation='relu'))\n",
    "top_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.add(top_model)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-5), metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1198 samples, validate on 300 samples\n",
      "Epoch 1/25\n",
      "1198/1198 [==============================] - 1030s 860ms/step - loss: 0.6353 - acc: 0.6828 - val_loss: 0.6058 - val_acc: 0.6933\n",
      "Epoch 2/25\n",
      "1198/1198 [==============================] - 1029s 859ms/step - loss: 0.5479 - acc: 0.7112 - val_loss: 0.6012 - val_acc: 0.6967\n",
      "Epoch 3/25\n",
      "1198/1198 [==============================] - 1031s 860ms/step - loss: 0.4750 - acc: 0.7604 - val_loss: 0.6134 - val_acc: 0.6667\n",
      "Epoch 4/25\n",
      "1198/1198 [==============================] - 1030s 860ms/step - loss: 0.3965 - acc: 0.8322 - val_loss: 0.6196 - val_acc: 0.6900\n",
      "Epoch 5/25\n",
      "1198/1198 [==============================] - 1030s 860ms/step - loss: 0.3140 - acc: 0.8823 - val_loss: 0.6786 - val_acc: 0.6600\n",
      "Epoch 6/25\n",
      "1198/1198 [==============================] - 1030s 859ms/step - loss: 0.2266 - acc: 0.9332 - val_loss: 0.7583 - val_acc: 0.6867\n",
      "Epoch 7/25\n",
      "1198/1198 [==============================] - 1030s 860ms/step - loss: 0.1578 - acc: 0.9541 - val_loss: 0.8681 - val_acc: 0.6600\n",
      "Epoch 8/25\n",
      "1198/1198 [==============================] - 1036s 864ms/step - loss: 0.1110 - acc: 0.9716 - val_loss: 0.9438 - val_acc: 0.6533\n",
      "Epoch 9/25\n",
      "1198/1198 [==============================] - 1031s 861ms/step - loss: 0.0979 - acc: 0.9750 - val_loss: 1.0361 - val_acc: 0.6900\n",
      "Epoch 10/25\n",
      "1198/1198 [==============================] - 1031s 861ms/step - loss: 0.0726 - acc: 0.9808 - val_loss: 1.0611 - val_acc: 0.6967\n",
      "Epoch 11/25\n",
      "1198/1198 [==============================] - 1032s 861ms/step - loss: 0.0614 - acc: 0.9883 - val_loss: 1.0913 - val_acc: 0.6900\n",
      "Epoch 12/25\n",
      "1198/1198 [==============================] - 1031s 861ms/step - loss: 0.0493 - acc: 0.9875 - val_loss: 1.1632 - val_acc: 0.6533\n",
      "Epoch 13/25\n",
      "1198/1198 [==============================] - 1030s 860ms/step - loss: 0.0505 - acc: 0.9841 - val_loss: 1.2016 - val_acc: 0.6833\n",
      "Epoch 14/25\n",
      "1198/1198 [==============================] - 1030s 860ms/step - loss: 0.0513 - acc: 0.9866 - val_loss: 1.2566 - val_acc: 0.6900\n",
      "Epoch 15/25\n",
      "1198/1198 [==============================] - 1031s 861ms/step - loss: 0.0515 - acc: 0.9891 - val_loss: 1.0866 - val_acc: 0.6967\n",
      "Epoch 16/25\n",
      "1198/1198 [==============================] - 1035s 864ms/step - loss: 0.0374 - acc: 0.9900 - val_loss: 1.3018 - val_acc: 0.6767\n",
      "Epoch 17/25\n",
      "1198/1198 [==============================] - 1031s 861ms/step - loss: 0.0411 - acc: 0.9833 - val_loss: 1.2046 - val_acc: 0.7000\n",
      "Epoch 18/25\n",
      "1198/1198 [==============================] - 1031s 860ms/step - loss: 0.0245 - acc: 0.9933 - val_loss: 1.3160 - val_acc: 0.6800\n",
      "Epoch 19/25\n",
      "1198/1198 [==============================] - 1032s 861ms/step - loss: 0.0203 - acc: 0.9950 - val_loss: 1.3234 - val_acc: 0.6733\n",
      "Epoch 20/25\n",
      "1198/1198 [==============================] - 1030s 860ms/step - loss: 0.0213 - acc: 0.9933 - val_loss: 1.3757 - val_acc: 0.6300\n",
      "Epoch 21/25\n",
      "1198/1198 [==============================] - 1030s 860ms/step - loss: 0.0217 - acc: 0.9933 - val_loss: 1.3241 - val_acc: 0.6700\n",
      "Epoch 22/25\n",
      "1198/1198 [==============================] - 1031s 860ms/step - loss: 0.0287 - acc: 0.9900 - val_loss: 1.2868 - val_acc: 0.6633\n",
      "Epoch 23/25\n",
      "1198/1198 [==============================] - 1033s 862ms/step - loss: 0.0293 - acc: 0.9908 - val_loss: 1.2732 - val_acc: 0.6700\n",
      "Epoch 24/25\n",
      "1198/1198 [==============================] - 1029s 859ms/step - loss: 0.0198 - acc: 0.9950 - val_loss: 1.3887 - val_acc: 0.6700\n",
      "Epoch 25/25\n",
      "1198/1198 [==============================] - 1028s 858ms/step - loss: 0.0261 - acc: 0.9942 - val_loss: 1.3161 - val_acc: 0.6533\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=64, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.3160930077234905\n",
      "Test accuracy: 0.6533333341280619\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Binary Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,epochs+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1198, 128, 128, 3)\n",
      "x_test shape: (300, 128, 128, 3)\n",
      "1198 train samples\n",
      "300 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(img_array, class_labels, test_size=0.20, stratify=class_labels)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing the data\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "\n",
    "nb_train_samples = x_train.shape[0]\n",
    "nb_validation_samples = x_test.shape[0]\n",
    "num_classes = 2\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 128, 128\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "    \n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "# this function is used to update the plots for each epoch and error\n",
    "def plt_dynamic(x, vy, ty, ax, fig):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 42s 0us/step\n"
     ]
    }
   ],
   "source": [
    "resnet_model = ResNet50(weights='imagenet',include_top=False,input_shape=x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 134, 134, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 64, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 64, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 66, 66, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 32, 32, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 32, 32, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 32, 32, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 32, 32, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 32, 32, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 32, 32, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 32, 32, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 32, 32, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 32, 32, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 32, 32, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 32, 32, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 32, 32, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 32, 32, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 32, 32, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 32, 32, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 32, 32, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 32, 32, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 32, 32, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 32, 32, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 32, 32, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 16, 16, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 16, 16, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 16, 16, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 16, 16, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 16, 16, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 16, 16, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 16, 16, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 16, 16, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 16, 16, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 16, 16, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 16, 16, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 16, 16, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 16, 16, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 16, 16, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 16, 16, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 16, 16, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 16, 16, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 16, 16, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 16, 16, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 16, 16, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 16, 16, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 16, 16, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 16, 16, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 16, 16, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 16, 16, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 16, 16, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 8, 8, 256)    131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 8, 8, 1024)   525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 8, 8, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 8, 8, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 8, 8, 256)    262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 1024)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 8, 8, 256)    262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 1024)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 8, 8, 256)    262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 1024)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 8, 8, 256)    262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 1024)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 8, 8, 256)    262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 8, 8, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 8, 8, 1024)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 4, 4, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 4, 4, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 4, 4, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 4, 4, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 4, 4, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 4, 4, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 4, 4, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 4, 4, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 4, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 4, 4, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 4, 4, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 4, 4, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 4, 4, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 4, 4, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 4, 4, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 4, 4, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 4, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 4, 4, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 4, 4, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 4, 4, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 4, 4, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 4, 4, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 4, 4, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 4, 4, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 2048)   0           add_16[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 2)                 8389378   \n",
      "=================================================================\n",
      "Total params: 31,977,090\n",
      "Trainable params: 31,923,970\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#for layer in vgg16_model.layers[7:]:\n",
    "#    layer.trainable = False\n",
    "    \n",
    "model=Sequential()\n",
    "model.add(resnet_model)\n",
    "\n",
    "\n",
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=(4, 4, 2048)))\n",
    "#model_aug.add(Dropout(0.3))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.add(top_model)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-5), metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1198 samples, validate on 300 samples\n",
      "Epoch 1/5\n",
      "1198/1198 [==============================] - 1258s 1s/step - loss: 1.0217 - acc: 0.6194 - val_loss: 0.9310 - val_acc: 0.6433\n",
      "Epoch 2/5\n",
      "1198/1198 [==============================] - 1179s 984ms/step - loss: 0.2930 - acc: 0.8815 - val_loss: 0.9000 - val_acc: 0.6400\n",
      "Epoch 3/5\n",
      "1198/1198 [==============================] - 1378s 1s/step - loss: 0.1155 - acc: 0.9800 - val_loss: 0.9100 - val_acc: 0.6633\n",
      "Epoch 4/5\n",
      "1198/1198 [==============================] - 1360s 1s/step - loss: 0.0739 - acc: 0.9900 - val_loss: 0.9410 - val_acc: 0.6733\n",
      "Epoch 5/5\n",
      "1198/1198 [==============================] - 1167s 974ms/step - loss: 0.0477 - acc: 0.9983 - val_loss: 0.9485 - val_acc: 0.6600\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=64, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9485485943158468\n",
      "Test accuracy: 0.6600000007947286\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Binary Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,epochs+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResNet50(weights='imagenet',include_top=False,input_shape=x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1b80e632ba8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x1b80e632eb8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1b80e632f28>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1b81527d278>,\n",
       " <keras.layers.core.Activation at 0x1b81527d048>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model.layers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResNet50(weights='imagenet',include_top=False,input_shape=x_train.shape[1:])\n",
    "del model\n",
    "del top_model\n",
    "for layer in resnet_model.layers[14:]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "sequential_6 (Sequential)    (None, 2)                 8389378   \n",
      "=================================================================\n",
      "Total params: 31,977,090\n",
      "Trainable params: 8,456,962\n",
      "Non-trainable params: 23,520,128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#for layer in vgg16_model.layers[7:]:\n",
    "#    layer.trainable = False\n",
    "    \n",
    "model=Sequential()\n",
    "model.add(resnet_model)\n",
    "\n",
    "\n",
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=(4, 4, 2048)))\n",
    "#model_aug.add(Dropout(0.3))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.add(top_model)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-5), metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1198 samples, validate on 300 samples\n",
      "Epoch 1/30\n",
      "1198/1198 [==============================] - 1131s 944ms/step - loss: 1.0604 - acc: 0.5835 - val_loss: 1.1431 - val_acc: 0.6067\n",
      "Epoch 2/30\n",
      "1198/1198 [==============================] - 1051s 877ms/step - loss: 0.6068 - acc: 0.7429 - val_loss: 1.0886 - val_acc: 0.6233\n",
      "Epoch 3/30\n",
      "1198/1198 [==============================] - 1050s 877ms/step - loss: 0.3985 - acc: 0.8139 - val_loss: 1.0911 - val_acc: 0.6300\n",
      "Epoch 4/30\n",
      "1198/1198 [==============================] - 1052s 878ms/step - loss: 0.2731 - acc: 0.8873 - val_loss: 1.0742 - val_acc: 0.6433\n",
      "Epoch 5/30\n",
      "1198/1198 [==============================] - 1045s 872ms/step - loss: 0.2101 - acc: 0.9274 - val_loss: 1.0644 - val_acc: 0.6600\n",
      "Epoch 6/30\n",
      "1198/1198 [==============================] - 1020s 852ms/step - loss: 0.1569 - acc: 0.9608 - val_loss: 1.0825 - val_acc: 0.6500\n",
      "Epoch 7/30\n",
      "1198/1198 [==============================] - 1022s 853ms/step - loss: 0.1304 - acc: 0.9750 - val_loss: 1.0890 - val_acc: 0.6467\n",
      "Epoch 8/30\n",
      "1198/1198 [==============================] - 1020s 851ms/step - loss: 0.1016 - acc: 0.9841 - val_loss: 1.1191 - val_acc: 0.6467\n",
      "Epoch 9/30\n",
      "1198/1198 [==============================] - 1024s 854ms/step - loss: 0.0917 - acc: 0.9875 - val_loss: 1.1073 - val_acc: 0.6567\n",
      "Epoch 10/30\n",
      "1198/1198 [==============================] - 1021s 853ms/step - loss: 0.0804 - acc: 0.9883 - val_loss: 1.1089 - val_acc: 0.6500\n",
      "Epoch 11/30\n",
      "1198/1198 [==============================] - 1021s 852ms/step - loss: 0.0699 - acc: 0.9908 - val_loss: 1.1272 - val_acc: 0.6567\n",
      "Epoch 12/30\n",
      "1198/1198 [==============================] - 1020s 852ms/step - loss: 0.0617 - acc: 0.9875 - val_loss: 1.1417 - val_acc: 0.6533\n",
      "Epoch 13/30\n",
      "1198/1198 [==============================] - 1019s 851ms/step - loss: 0.0546 - acc: 0.9925 - val_loss: 1.1473 - val_acc: 0.6600\n",
      "Epoch 14/30\n",
      "1198/1198 [==============================] - 1022s 853ms/step - loss: 0.0509 - acc: 0.9908 - val_loss: 1.1623 - val_acc: 0.6700\n",
      "Epoch 15/30\n",
      "1198/1198 [==============================] - 1020s 851ms/step - loss: 0.0448 - acc: 0.9958 - val_loss: 1.1737 - val_acc: 0.6667\n",
      "Epoch 16/30\n",
      "1198/1198 [==============================] - 1020s 851ms/step - loss: 0.0449 - acc: 0.9917 - val_loss: 1.1910 - val_acc: 0.6667\n",
      "Epoch 17/30\n",
      "1198/1198 [==============================] - 1021s 852ms/step - loss: 0.0340 - acc: 0.9967 - val_loss: 1.1764 - val_acc: 0.6600\n",
      "Epoch 18/30\n",
      "1198/1198 [==============================] - 1020s 852ms/step - loss: 0.0304 - acc: 0.9983 - val_loss: 1.1964 - val_acc: 0.6600\n",
      "Epoch 19/30\n",
      "1198/1198 [==============================] - 1019s 851ms/step - loss: 0.0290 - acc: 0.9992 - val_loss: 1.2021 - val_acc: 0.6567\n",
      "Epoch 20/30\n",
      "1198/1198 [==============================] - 1023s 854ms/step - loss: 0.0314 - acc: 0.9958 - val_loss: 1.2080 - val_acc: 0.6667\n",
      "Epoch 21/30\n",
      "1198/1198 [==============================] - 1023s 854ms/step - loss: 0.0299 - acc: 0.9958 - val_loss: 1.2069 - val_acc: 0.6600\n",
      "Epoch 22/30\n",
      "1198/1198 [==============================] - 1019s 851ms/step - loss: 0.0323 - acc: 0.9925 - val_loss: 1.2034 - val_acc: 0.6633\n",
      "Epoch 23/30\n",
      "1198/1198 [==============================] - 1023s 854ms/step - loss: 0.0242 - acc: 0.9983 - val_loss: 1.2190 - val_acc: 0.6600\n",
      "Epoch 24/30\n",
      "1198/1198 [==============================] - 1019s 851ms/step - loss: 0.0215 - acc: 0.9958 - val_loss: 1.2199 - val_acc: 0.6600\n",
      "Epoch 25/30\n",
      "1198/1198 [==============================] - 1020s 852ms/step - loss: 0.0223 - acc: 0.9967 - val_loss: 1.2274 - val_acc: 0.6633\n",
      "Epoch 26/30\n",
      "1198/1198 [==============================] - 1021s 853ms/step - loss: 0.0201 - acc: 0.9983 - val_loss: 1.2627 - val_acc: 0.6767\n",
      "Epoch 27/30\n",
      "1198/1198 [==============================] - 1020s 852ms/step - loss: 0.0223 - acc: 0.9950 - val_loss: 1.2186 - val_acc: 0.6633\n",
      "Epoch 28/30\n",
      "1198/1198 [==============================] - 1024s 854ms/step - loss: 0.0192 - acc: 0.9967 - val_loss: 1.2731 - val_acc: 0.6800\n",
      "Epoch 29/30\n",
      "1198/1198 [==============================] - 1021s 852ms/step - loss: 0.0215 - acc: 0.9950 - val_loss: 1.2464 - val_acc: 0.6633\n",
      "Epoch 30/30\n",
      "1198/1198 [==============================] - 1021s 853ms/step - loss: 0.0163 - acc: 0.9983 - val_loss: 1.2658 - val_acc: 0.6667\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=64, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.2657503199577331\n",
      "Test accuracy: 0.6666666666666666\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (5,) and (30,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-54dbee23864a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mvy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mplt_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-ede14ee08064>\u001b[0m in \u001b[0;36mplt_dynamic\u001b[1;34m(x, vy, ty, ax, fig)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# this function is used to update the plots for each epoch and error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplt_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Validation Loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Train Loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1527\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 242\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (5,) and (30,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Binary Crossentropy Loss')\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1123, 128, 128, 3)\n",
      "x_test shape: (375, 128, 128, 3)\n",
      "1123 train samples\n",
      "375 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(img_array, class_labels, test_size=0.25, stratify=class_labels)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing the data\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "\n",
    "nb_train_samples = x_train.shape[0]\n",
    "nb_validation_samples = x_test.shape[0]\n",
    "num_classes = 2\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 128, 128\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "    \n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "# this function is used to update the plots for each epoch and error\n",
    "def plt_dynamic(x, vy, ty, ax, fig):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 2)                 2097346   \n",
      "=================================================================\n",
      "Total params: 25,685,058\n",
      "Trainable params: 2,097,346\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1123 samples, validate on 375 samples\n",
      "Epoch 1/30\n",
      "1123/1123 [==============================] - 659s 587ms/step - loss: 0.9253 - acc: 0.6251 - val_loss: 0.6201 - val_acc: 0.6987\n",
      "Epoch 2/30\n",
      "1123/1123 [==============================] - 786s 700ms/step - loss: 0.3625 - acc: 0.8477 - val_loss: 0.6353 - val_acc: 0.6987\n",
      "Epoch 3/30\n",
      "1123/1123 [==============================] - 788s 702ms/step - loss: 0.1937 - acc: 0.9466 - val_loss: 0.6941 - val_acc: 0.6987\n",
      "Epoch 4/30\n",
      "1123/1123 [==============================] - 787s 700ms/step - loss: 0.0992 - acc: 0.9786 - val_loss: 0.7315 - val_acc: 0.6987\n",
      "Epoch 5/30\n",
      "1123/1123 [==============================] - 591s 526ms/step - loss: 0.0587 - acc: 0.9929 - val_loss: 0.7736 - val_acc: 0.6987\n",
      "Epoch 6/30\n",
      "1123/1123 [==============================] - 308s 275ms/step - loss: 0.0410 - acc: 0.9955 - val_loss: 0.7949 - val_acc: 0.6987\n",
      "Epoch 7/30\n",
      "1123/1123 [==============================] - 306s 273ms/step - loss: 0.0344 - acc: 0.9938 - val_loss: 0.8219 - val_acc: 0.6987\n",
      "Epoch 8/30\n",
      "1123/1123 [==============================] - 305s 272ms/step - loss: 0.0230 - acc: 0.9991 - val_loss: 0.8344 - val_acc: 0.6987\n",
      "Epoch 9/30\n",
      "1123/1123 [==============================] - 308s 274ms/step - loss: 0.0215 - acc: 0.9982 - val_loss: 0.8741 - val_acc: 0.6987\n",
      "Epoch 10/30\n",
      "1123/1123 [==============================] - 306s 272ms/step - loss: 0.0176 - acc: 0.9982 - val_loss: 0.8818 - val_acc: 0.6987\n",
      "Epoch 11/30\n",
      "1123/1123 [==============================] - 305s 271ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.8926 - val_acc: 0.6987\n",
      "Epoch 12/30\n",
      "1123/1123 [==============================] - 305s 271ms/step - loss: 0.0127 - acc: 0.9991 - val_loss: 0.9158 - val_acc: 0.6987\n",
      "Epoch 13/30\n",
      "1123/1123 [==============================] - 304s 271ms/step - loss: 0.0102 - acc: 0.9991 - val_loss: 0.9289 - val_acc: 0.6987\n",
      "Epoch 14/30\n",
      "1123/1123 [==============================] - 304s 271ms/step - loss: 0.0108 - acc: 0.9982 - val_loss: 0.9420 - val_acc: 0.6987\n",
      "Epoch 15/30\n",
      "1123/1123 [==============================] - 304s 270ms/step - loss: 0.0103 - acc: 0.9991 - val_loss: 0.9575 - val_acc: 0.6987\n",
      "Epoch 16/30\n",
      "1123/1123 [==============================] - 304s 271ms/step - loss: 0.0092 - acc: 0.9982 - val_loss: 0.9615 - val_acc: 0.6987\n",
      "Epoch 17/30\n",
      "1123/1123 [==============================] - 304s 271ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.9794 - val_acc: 0.6987\n",
      "Epoch 18/30\n",
      "1123/1123 [==============================] - 304s 270ms/step - loss: 0.0067 - acc: 0.9991 - val_loss: 0.9935 - val_acc: 0.6987\n",
      "Epoch 19/30\n",
      "1123/1123 [==============================] - 304s 271ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.9977 - val_acc: 0.6987\n",
      "Epoch 20/30\n",
      "1123/1123 [==============================] - 305s 272ms/step - loss: 0.0063 - acc: 0.9991 - val_loss: 0.9993 - val_acc: 0.6987\n",
      "Epoch 21/30\n",
      "1123/1123 [==============================] - 304s 271ms/step - loss: 0.0069 - acc: 0.9982 - val_loss: 1.0006 - val_acc: 0.6987\n",
      "Epoch 22/30\n",
      "1123/1123 [==============================] - 304s 271ms/step - loss: 0.0058 - acc: 0.9991 - val_loss: 1.0098 - val_acc: 0.6987\n",
      "Epoch 23/30\n",
      "1123/1123 [==============================] - 304s 271ms/step - loss: 0.0089 - acc: 0.9973 - val_loss: 1.0397 - val_acc: 0.6987\n",
      "Epoch 24/30\n",
      "1123/1123 [==============================] - 304s 271ms/step - loss: 0.0077 - acc: 0.9973 - val_loss: 1.0119 - val_acc: 0.6987\n",
      "Epoch 25/30\n",
      "1123/1123 [==============================] - 305s 271ms/step - loss: 0.0063 - acc: 0.9982 - val_loss: 1.0354 - val_acc: 0.6987\n",
      "Epoch 26/30\n",
      "1123/1123 [==============================] - 304s 271ms/step - loss: 0.0061 - acc: 0.9991 - val_loss: 1.0549 - val_acc: 0.6987\n",
      "Epoch 27/30\n",
      "1123/1123 [==============================] - 305s 272ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 1.0357 - val_acc: 0.6987\n",
      "Epoch 28/30\n",
      "1123/1123 [==============================] - 305s 272ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 1.0591 - val_acc: 0.6987\n",
      "Epoch 29/30\n",
      "1123/1123 [==============================] - 305s 272ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 1.0760 - val_acc: 0.6987\n",
      "Epoch 30/30\n",
      "1123/1123 [==============================] - 305s 272ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 1.0645 - val_acc: 0.6987\n"
     ]
    }
   ],
   "source": [
    "resnet_model = ResNet50(weights='imagenet',include_top=False,input_shape=x_train.shape[1:])\n",
    "#del model\n",
    "#del top_model\n",
    "for layer in resnet_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "#for layer in vgg16_model.layers[7:]:\n",
    "#    layer.trainable = False\n",
    "    \n",
    "model=Sequential()\n",
    "model.add(resnet_model)\n",
    "\n",
    "\n",
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=(4, 4, 2048)))\n",
    "#model_aug.add(Dropout(0.3))\n",
    "top_model.add(Dense(64, activation='relu'))\n",
    "top_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.add(top_model)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-4), metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "epochs = 30\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=128, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0644841674168906\n",
      "Test accuracy: 0.6986666674613953\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 2)                 2228418   \n",
      "=================================================================\n",
      "Total params: 25,816,130\n",
      "Trainable params: 2,162,882\n",
      "Non-trainable params: 23,653,248\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "resnet_model = ResNet50(weights='imagenet',include_top=False,input_shape=x_train.shape[1:])\n",
    "del model\n",
    "del top_model\n",
    "for layer in resnet_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "#for layer in vgg16_model.layers[7:]:\n",
    "#    layer.trainable = False\n",
    "    \n",
    "model=Sequential()\n",
    "model.add(resnet_model)\n",
    "\n",
    "\n",
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=(4, 4, 2048)))\n",
    "#model_aug.add(Dropout(0.3))\n",
    "top_model.add(BatchNormalization())\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(64, activation='relu'))\n",
    "top_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.add(top_model)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-5), metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "17/17 [==============================] - 195s 11s/step - loss: 0.9043 - acc: 0.6471 - val_loss: 0.6109 - val_acc: 0.6987\n",
      "Epoch 2/8\n",
      "17/17 [==============================] - 189s 11s/step - loss: 0.8809 - acc: 0.6618 - val_loss: 0.6109 - val_acc: 0.6987\n",
      "Epoch 3/8\n",
      "17/17 [==============================] - 185s 11s/step - loss: 0.8868 - acc: 0.6587 - val_loss: 0.6120 - val_acc: 0.6987\n",
      "Epoch 4/8\n",
      "17/17 [==============================] - 187s 11s/step - loss: 0.9062 - acc: 0.6360 - val_loss: 0.6175 - val_acc: 0.6987\n",
      "Epoch 5/8\n",
      "17/17 [==============================] - 181s 11s/step - loss: 0.9018 - acc: 0.6607 - val_loss: 0.6252 - val_acc: 0.6987\n",
      "Epoch 6/8\n",
      "17/17 [==============================] - 191s 11s/step - loss: 0.7858 - acc: 0.6783 - val_loss: 0.6409 - val_acc: 0.6987\n",
      "Epoch 7/8\n",
      "17/17 [==============================] - 193s 11s/step - loss: 0.8321 - acc: 0.6476 - val_loss: 0.6540 - val_acc: 0.6987\n",
      "Epoch 8/8\n",
      "17/17 [==============================] - 189s 11s/step - loss: 0.8266 - acc: 0.6562 - val_loss: 0.6662 - val_acc: 0.6987\n"
     ]
    }
   ],
   "source": [
    "epochs = 8\n",
    "batch_size = 64\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history=model.fit_generator(datagen.flow(x_train, y_train),\n",
    "                    steps_per_epoch=nb_train_samples // batch_size, epochs=epochs,validation_data=(x_test, y_test),\n",
    "                           validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.666226343313853\n",
      "Test accuracy: 0.6986666650772094\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 2)                 2101762   \n",
      "=================================================================\n",
      "Total params: 25,689,474\n",
      "Trainable params: 2,101,634\n",
      "Non-trainable params: 23,587,840\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "resnet_model = ResNet50(weights='imagenet',include_top=False,input_shape=x_train.shape[1:])\n",
    "del model\n",
    "del top_model\n",
    "for layer in resnet_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "#for layer in vgg16_model.layers[7:]:\n",
    "#    layer.trainable = False\n",
    "    \n",
    "model=Sequential()\n",
    "model.add(resnet_model)\n",
    "\n",
    "\n",
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=(4, 4, 2048)))\n",
    "#model_aug.add(Dropout(0.3))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Denout(0.2))\n",
    "top_model.add(Densse(64, activation='relu'))\n",
    "top_model.add(Drope(64, activation='relu',kernel_initializer='he_normal'))\n",
    "top_model.add(BatchNormalization())\n",
    "top_model.add(Dense(2, activation='softmax',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(top_model)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-6), metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "17/17 [==============================] - 192s 11s/step - loss: 0.9006 - acc: 0.5735 - val_loss: 0.6374 - val_acc: 0.6987\n",
      "Epoch 2/35\n",
      "17/17 [==============================] - 189s 11s/step - loss: 0.9582 - acc: 0.5276 - val_loss: 0.6389 - val_acc: 0.6987\n",
      "Epoch 3/35\n",
      "17/17 [==============================] - 183s 11s/step - loss: 0.9710 - acc: 0.5257 - val_loss: 0.6350 - val_acc: 0.6987\n",
      "Epoch 4/35\n",
      "17/17 [==============================] - 189s 11s/step - loss: 0.9823 - acc: 0.5386 - val_loss: 0.6312 - val_acc: 0.6987\n",
      "Epoch 5/35\n",
      "17/17 [==============================] - 183s 11s/step - loss: 0.9168 - acc: 0.5220 - val_loss: 0.6310 - val_acc: 0.6987\n",
      "Epoch 6/35\n",
      "17/17 [==============================] - 189s 11s/step - loss: 0.9641 - acc: 0.5441 - val_loss: 0.6292 - val_acc: 0.6987\n",
      "Epoch 7/35\n",
      "17/17 [==============================] - 186s 11s/step - loss: 0.9380 - acc: 0.5018 - val_loss: 0.6283 - val_acc: 0.6987\n",
      "Epoch 8/35\n",
      "17/17 [==============================] - 189s 11s/step - loss: 0.9584 - acc: 0.5018 - val_loss: 0.6275 - val_acc: 0.6987\n",
      "Epoch 9/35\n",
      "17/17 [==============================] - 183s 11s/step - loss: 0.9222 - acc: 0.5593 - val_loss: 0.6266 - val_acc: 0.6987\n",
      "Epoch 10/35\n",
      "17/17 [==============================] - 189s 11s/step - loss: 1.0298 - acc: 0.5074 - val_loss: 0.6262 - val_acc: 0.6987\n",
      "Epoch 11/35\n",
      "17/17 [==============================] - 183s 11s/step - loss: 0.9949 - acc: 0.5239 - val_loss: 0.6261 - val_acc: 0.6987\n",
      "Epoch 12/35\n",
      "17/17 [==============================] - 190s 11s/step - loss: 0.9495 - acc: 0.5037 - val_loss: 0.6257 - val_acc: 0.6987\n",
      "Epoch 13/35\n",
      "17/17 [==============================] - 183s 11s/step - loss: 0.9002 - acc: 0.5554 - val_loss: 0.6260 - val_acc: 0.6987\n",
      "Epoch 14/35\n",
      "17/17 [==============================] - 189s 11s/step - loss: 0.9735 - acc: 0.5000 - val_loss: 0.6256 - val_acc: 0.6987\n",
      "Epoch 15/35\n",
      "17/17 [==============================] - 183s 11s/step - loss: 0.9821 - acc: 0.5018 - val_loss: 0.6258 - val_acc: 0.6987\n",
      "Epoch 16/35\n",
      "17/17 [==============================] - 190s 11s/step - loss: 0.9313 - acc: 0.5588 - val_loss: 0.6262 - val_acc: 0.6987\n",
      "Epoch 17/35\n",
      "17/17 [==============================] - 183s 11s/step - loss: 0.9751 - acc: 0.5167 - val_loss: 0.6263 - val_acc: 0.6987\n",
      "Epoch 18/35\n",
      "17/17 [==============================] - 189s 11s/step - loss: 0.9063 - acc: 0.5533 - val_loss: 0.6264 - val_acc: 0.6987\n",
      "Epoch 19/35\n",
      "17/17 [==============================] - 189s 11s/step - loss: 0.9753 - acc: 0.4871 - val_loss: 0.6260 - val_acc: 0.6987\n",
      "Epoch 20/35\n",
      "17/17 [==============================] - 184s 11s/step - loss: 0.9677 - acc: 0.5075 - val_loss: 0.6249 - val_acc: 0.6987\n",
      "Epoch 21/35\n",
      "17/17 [==============================] - 195s 11s/step - loss: 0.9973 - acc: 0.4945 - val_loss: 0.6246 - val_acc: 0.6987\n",
      "Epoch 22/35\n",
      "17/17 [==============================] - 183s 11s/step - loss: 0.8880 - acc: 0.5501 - val_loss: 0.6250 - val_acc: 0.6987\n",
      "Epoch 23/35\n",
      "17/17 [==============================] - 189s 11s/step - loss: 0.9369 - acc: 0.5386 - val_loss: 0.6257 - val_acc: 0.6987\n",
      "Epoch 24/35\n",
      "17/17 [==============================] - 184s 11s/step - loss: 0.9054 - acc: 0.5296 - val_loss: 0.6258 - val_acc: 0.6987\n",
      "Epoch 25/35\n",
      "17/17 [==============================] - 189s 11s/step - loss: 0.9438 - acc: 0.5368 - val_loss: 0.6260 - val_acc: 0.6987\n",
      "Epoch 26/35\n",
      "17/17 [==============================] - 183s 11s/step - loss: 0.9574 - acc: 0.5089 - val_loss: 0.6264 - val_acc: 0.6987\n",
      "Epoch 27/35\n",
      "17/17 [==============================] - 190s 11s/step - loss: 0.9060 - acc: 0.5478 - val_loss: 0.6263 - val_acc: 0.6987\n",
      "Epoch 28/35\n",
      "17/17 [==============================] - 184s 11s/step - loss: 0.9224 - acc: 0.5442 - val_loss: 0.6258 - val_acc: 0.6987\n",
      "Epoch 29/35\n",
      "17/17 [==============================] - 190s 11s/step - loss: 0.9933 - acc: 0.4724 - val_loss: 0.6261 - val_acc: 0.6987\n",
      "Epoch 30/35\n",
      "17/17 [==============================] - 184s 11s/step - loss: 0.9876 - acc: 0.5110 - val_loss: 0.6247 - val_acc: 0.6987\n",
      "Epoch 31/35\n",
      "17/17 [==============================] - 189s 11s/step - loss: 0.9145 - acc: 0.5202 - val_loss: 0.6253 - val_acc: 0.6987\n",
      "Epoch 32/35\n",
      "17/17 [==============================] - 183s 11s/step - loss: 0.9808 - acc: 0.5573 - val_loss: 0.6254 - val_acc: 0.6987\n",
      "Epoch 33/35\n",
      "17/17 [==============================] - 189s 11s/step - loss: 0.9064 - acc: 0.5496 - val_loss: 0.6248 - val_acc: 0.6987\n",
      "Epoch 34/35\n",
      "17/17 [==============================] - 184s 11s/step - loss: 0.9259 - acc: 0.5331 - val_loss: 0.6234 - val_acc: 0.6987\n",
      "Epoch 35/35\n",
      "17/17 [==============================] - 189s 11s/step - loss: 0.9452 - acc: 0.5184 - val_loss: 0.6237 - val_acc: 0.6987\n"
     ]
    }
   ],
   "source": [
    "epochs = 35\n",
    "batch_size = 64\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.28,\n",
    "        zoom_range=0.25,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history=model.fit_generator(datagen.flow(x_train, y_train),\n",
    "                    steps_per_epoch=nb_train_samples // batch_size, epochs=epochs,validation_data=(x_test, y_test),\n",
    "                           validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6237001342773437\n",
      "Test accuracy: 0.6986666661898295\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1123, 128, 128, 3)\n",
      "x_test shape: (375, 128, 128, 3)\n",
      "1123 train samples\n",
      "375 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(img_array, class_labels, test_size=0.25, stratify=class_labels)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing the data\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "\n",
    "nb_train_samples = x_train.shape[0]\n",
    "nb_validation_samples = x_test.shape[0]\n",
    "num_classes = 2\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 128, 128\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "    \n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "# this function is used to update the plots for each epoch and error\n",
    "def plt_dynamic(x, vy, ty, ax, fig):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 85s 1us/step\n"
     ]
    }
   ],
   "source": [
    "inception_model = InceptionV3(include_top=False, weights='imagenet', input_shape=x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 63, 63, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 63, 63, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 63, 63, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 61, 61, 32)   9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 61, 61, 32)   96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 61, 61, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 61, 61, 64)   18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 61, 61, 64)   192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 61, 61, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 30, 30, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 30, 30, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 30, 30, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 30, 30, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 28, 28, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 28, 28, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 28, 28, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 13, 13, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 13, 13, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 13, 13, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 13, 13, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 13, 13, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 13, 13, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 13, 13, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 13, 13, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 13, 13, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 13, 13, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 13, 13, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 13, 13, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 13, 13, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 13, 13, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 13, 13, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 13, 13, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 13, 13, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 13, 13, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 13, 13, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 13, 13, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 13, 13, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 13, 13, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 13, 13, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 13, 13, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 13, 13, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 13, 13, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 13, 13, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 13, 13, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 13, 13, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 13, 13, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 13, 13, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 13, 13, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 13, 13, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 13, 13, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 13, 13, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 13, 13, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 13, 13, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 13, 13, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 13, 13, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 13, 13, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 13, 13, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 13, 13, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 13, 13, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 13, 13, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 13, 13, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 13, 13, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 13, 13, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 13, 13, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 13, 13, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 13, 13, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 13, 13, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 13, 13, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 13, 13, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 13, 13, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 13, 13, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 13, 13, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 13, 13, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 13, 13, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 13, 13, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 13, 13, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 13, 13, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 13, 13, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 13, 13, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 13, 13, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 13, 13, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 13, 13, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 13, 13, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 13, 13, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 13, 13, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 13, 13, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 13, 13, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 13, 13, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 13, 13, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 13, 13, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 13, 13, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 6, 6, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 6, 6, 96)     82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 6, 6, 384)    1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 6, 6, 96)     288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 6, 6, 384)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 6, 6, 96)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 6, 6, 768)    0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 6, 6, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 6, 6, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 6, 6, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 6, 6, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 6, 6, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 6, 6, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 6, 6, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 6, 6, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 6, 6, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 6, 6, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 6, 6, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 6, 6, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 6, 6, 128)    114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 6, 6, 128)    114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 6, 6, 128)    384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 6, 6, 128)    384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 6, 6, 128)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 6, 6, 128)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 6, 6, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 6, 6, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 6, 6, 192)    172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 6, 6, 192)    172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 6, 6, 192)    576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 6, 6, 192)    576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 6, 6, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 6, 6, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 6, 6, 192)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 6, 6, 192)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 6, 6, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 6, 6, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 6, 6, 768)    0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 6, 6, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 6, 6, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 6, 6, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 6, 6, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 6, 6, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 6, 6, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 6, 6, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 6, 6, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 6, 6, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 6, 6, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 6, 6, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 6, 6, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 6, 6, 160)    179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 6, 6, 160)    179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 6, 6, 160)    480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 6, 6, 160)    480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 6, 6, 160)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 6, 6, 160)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 6, 6, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 6, 6, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 6, 6, 192)    215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 6, 6, 192)    215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 6, 6, 192)    576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 6, 6, 192)    576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 6, 6, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 6, 6, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 6, 6, 192)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 6, 6, 192)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 6, 6, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 6, 6, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 6, 6, 768)    0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 6, 6, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 6, 6, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 6, 6, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 6, 6, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 6, 6, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 6, 6, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 6, 6, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 6, 6, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 6, 6, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 6, 6, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 6, 6, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 6, 6, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 6, 6, 160)    179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 6, 6, 160)    179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 6, 6, 160)    480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 6, 6, 160)    480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 6, 6, 160)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 6, 6, 160)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 6, 6, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 6, 6, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 6, 6, 192)    215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 6, 6, 192)    215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 6, 6, 192)    576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 6, 6, 192)    576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 6, 6, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 6, 6, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 6, 6, 192)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 6, 6, 192)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 6, 6, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 6, 6, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 6, 6, 768)    0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 6, 6, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 6, 6, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 6, 6, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 6, 6, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 6, 6, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 6, 6, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 6, 6, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 6, 6, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 6, 6, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 6, 6, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 6, 6, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 6, 6, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 6, 6, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 6, 6, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 6, 6, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 6, 6, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 6, 6, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 6, 6, 192)    258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 6, 6, 192)    258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 6, 6, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 6, 6, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 6, 6, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 6, 6, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 6, 6, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 6, 6, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 6, 6, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 6, 6, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 6, 6, 768)    0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 6, 6, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 6, 6, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 6, 6, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 6, 6, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 6, 6, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 6, 6, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 6, 6, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 6, 6, 192)    258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 6, 6, 192)    576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 6, 6, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 6, 6, 192)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 6, 6, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 2, 2, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 2, 2, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 2, 2, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 2, 2, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 2, 2, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 2, 2, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 2, 2, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 2, 2, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 2, 2, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 2, 2, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 2, 2, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 2, 2, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 2, 2, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 2, 2, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 2, 2, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 2, 2, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 2, 2, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 2, 2, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 2, 2, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 2, 2, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 2, 2, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 2, 2, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 2, 2, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 2, 2, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 2, 2, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 2, 2, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 2, 2, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 2, 2, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 2, 2, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 2, 2, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 2, 2, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 2, 2, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 2, 2, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 2, 2, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 2, 2, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 2, 2, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 2, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 2, 2, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 2, 2, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 2, 2, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 2, 2, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 2, 2, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 2, 2, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 2, 2, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 2, 2, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 2, 2, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 2, 2, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 2, 2, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 2, 2, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 2, 2, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 2, 2, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 2, 2, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 2, 2, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 2, 2, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 2, 2, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 2, 2, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 2, 2, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 2, 2, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 2, 2, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 2, 2, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 2, 2, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 2, 2, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 2, 2, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 2, 2, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 2, 2, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 2, 2, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 2, 2, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2, 2, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 2, 2, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 2, 2, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x21745ded978>,\n",
       " <keras.layers.convolutional.Conv2D at 0x21745dd9cf8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x21745daf978>,\n",
       " <keras.layers.core.Activation at 0x21745d9ce80>,\n",
       " <keras.layers.convolutional.Conv2D at 0x21745d22630>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_model.layers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 2, 2, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 2)                 528642    \n",
      "=================================================================\n",
      "Total params: 22,331,426\n",
      "Trainable params: 557,218\n",
      "Non-trainable params: 21,774,208\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inception_model = InceptionV3(include_top=False, weights='imagenet', input_shape=x_train.shape[1:])\n",
    "#del model\n",
    "#del top_model\n",
    "for layer in inception_model.layers[8:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "#for layer in vgg16_model.layers[7:]:\n",
    "#    layer.trainable = False\n",
    "    \n",
    "model=Sequential()\n",
    "model.add(inception_model)\n",
    "\n",
    "\n",
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=(2, 2, 2048)))\n",
    "#model_aug.add(Dropout(0.3))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(64, activation='relu'))\n",
    "top_model.add(Dropout(0.2))\n",
    "top_model.add(Dense(64, activation='relu',kernel_initializer='he_normal'))\n",
    "top_model.add(Dense(2, activation='softmax',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(top_model)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-6), metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "17/17 [==============================] - 234s 14s/step - loss: 0.8611 - acc: 0.6581 - val_loss: 1.2986 - val_acc: 0.6960\n",
      "Epoch 2/6\n",
      "17/17 [==============================] - 219s 13s/step - loss: 0.7803 - acc: 0.6820 - val_loss: 1.2636 - val_acc: 0.6987\n",
      "Epoch 3/6\n",
      "17/17 [==============================] - 210s 12s/step - loss: 0.8298 - acc: 0.6456 - val_loss: 1.2252 - val_acc: 0.7013\n",
      "Epoch 4/6\n",
      "17/17 [==============================] - 220s 13s/step - loss: 0.8608 - acc: 0.6452 - val_loss: 1.1902 - val_acc: 0.6933\n",
      "Epoch 5/6\n",
      "17/17 [==============================] - 209s 12s/step - loss: 0.8434 - acc: 0.6402 - val_loss: 1.1539 - val_acc: 0.6933\n",
      "Epoch 6/6\n",
      "17/17 [==============================] - 218s 13s/step - loss: 0.7570 - acc: 0.7004 - val_loss: 1.1258 - val_acc: 0.6960\n"
     ]
    }
   ],
   "source": [
    "epochs = 6\n",
    "batch_size = 64\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.28,\n",
    "        zoom_range=0.25,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history=model.fit_generator(datagen.flow(x_train, y_train),\n",
    "                    steps_per_epoch=nb_train_samples // batch_size, epochs=epochs,validation_data=(x_test, y_test),\n",
    "                           validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.1257634963989258\n",
      "Test accuracy: 0.6960000001589457\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 2, 2, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "sequential_6 (Sequential)    (None, 2)                 2097922   \n",
      "=================================================================\n",
      "Total params: 23,900,706\n",
      "Trainable params: 2,108,034\n",
      "Non-trainable params: 21,792,672\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inception_model = InceptionV3(include_top=False, weights='imagenet', input_shape=x_train.shape[1:])\n",
    "del model\n",
    "del top_model\n",
    "for layer in inception_model.layers[5:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "#for layer in vgg16_model.layers[7:]:\n",
    "#    layer.trainable = False\n",
    "    \n",
    "model=Sequential()\n",
    "model.add(inception_model)\n",
    "\n",
    "\n",
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=(2, 2, 2048)))\n",
    "#model_aug.add(Dropout(0.3))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.2))\n",
    "top_model.add(Dense(2, activation='softmax',kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(top_model)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-6), metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 262s 15s/step - loss: 0.8564 - acc: 0.5790 - val_loss: 1.0196 - val_acc: 0.6053\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 239s 14s/step - loss: 0.7970 - acc: 0.6011 - val_loss: 1.0371 - val_acc: 0.6240\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 259s 15s/step - loss: 0.8293 - acc: 0.5663 - val_loss: 1.0487 - val_acc: 0.6240\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 272s 16s/step - loss: 0.8201 - acc: 0.5754 - val_loss: 1.0680 - val_acc: 0.6320\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 257s 15s/step - loss: 0.9253 - acc: 0.5514 - val_loss: 1.0868 - val_acc: 0.6427\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 269s 16s/step - loss: 0.8074 - acc: 0.5901 - val_loss: 1.0912 - val_acc: 0.6533\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 258s 15s/step - loss: 0.8792 - acc: 0.5774 - val_loss: 1.0823 - val_acc: 0.6453\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 270s 16s/step - loss: 0.8027 - acc: 0.6011 - val_loss: 1.0875 - val_acc: 0.6533\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 257s 15s/step - loss: 0.8164 - acc: 0.5866 - val_loss: 1.0981 - val_acc: 0.6507\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 270s 16s/step - loss: 0.8334 - acc: 0.6176 - val_loss: 1.0890 - val_acc: 0.6533\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 258s 15s/step - loss: 0.8205 - acc: 0.5997 - val_loss: 1.1093 - val_acc: 0.6613\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 272s 16s/step - loss: 0.8599 - acc: 0.5956 - val_loss: 1.1025 - val_acc: 0.6613\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 257s 15s/step - loss: 0.7910 - acc: 0.6423 - val_loss: 1.1080 - val_acc: 0.6533\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 270s 16s/step - loss: 0.8046 - acc: 0.6324 - val_loss: 1.1101 - val_acc: 0.6560\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 259s 15s/step - loss: 0.7922 - acc: 0.6290 - val_loss: 1.1035 - val_acc: 0.6560\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 267s 16s/step - loss: 0.8162 - acc: 0.6232 - val_loss: 1.0918 - val_acc: 0.6587\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 256s 15s/step - loss: 0.8075 - acc: 0.6236 - val_loss: 1.1026 - val_acc: 0.6560\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 270s 16s/step - loss: 0.7665 - acc: 0.6268 - val_loss: 1.1248 - val_acc: 0.6587\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 269s 16s/step - loss: 0.8225 - acc: 0.6121 - val_loss: 1.1271 - val_acc: 0.6587\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 259s 15s/step - loss: 0.8703 - acc: 0.5997 - val_loss: 1.1313 - val_acc: 0.6640\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.28,\n",
    "        zoom_range=0.25,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history=model.fit_generator(datagen.flow(x_train, y_train),\n",
    "                    steps_per_epoch=nb_train_samples // batch_size, epochs=epochs,validation_data=(x_test, y_test),\n",
    "                           validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.1312928546269734\n",
      "Test accuracy: 0.6640000014305115\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.1312928546269734\n",
      "Test accuracy: 0.6640000014305115\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Binary Crossentropy Loss')\n",
    "x = list(range(1,epochs+1))\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
